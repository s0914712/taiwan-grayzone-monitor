#!/usr/bin/env python3
"""
================================================================================
è»æ¼”é æ¸¬åˆ†æï¼šæš—èˆ¹æ´»å‹•ä½œç‚ºè»æ¼”é è­¦æŒ‡æ¨™
Exercise Prediction Analysis: Dark Vessel Activity as Early Warning Indicator
================================================================================

åŠŸèƒ½ï¼š
1. è®€å–æ¯æ—¥æš—èˆ¹åµæ¸¬è³‡æ–™ (dark_vessels.json)
2. å°ç…§å·²çŸ¥è»æ¼”äº‹ä»¶æ—¥æœŸ
3. è¨ˆç®—è»æ¼”å‰/ä¸­/å¾Œçš„æš—èˆ¹æ•¸é‡è®ŠåŒ–
4. è¨ˆç®—æ™‚é–“æ»¯å¾Œç›¸é—œæ€§ï¼ˆè‹¥æœ‰è¶³å¤ æ­·å²è³‡æ–™ï¼‰
5. ç”¢å‡º exercise_prediction.json ä¾› Dashboard ä½¿ç”¨

ç ”ç©¶å‡èªªï¼š
  è»æ¼”å‰ 7-14 å¤©ï¼Œå°ç£å‘¨é‚Šæš—èˆ¹æ•¸é‡å¯èƒ½å‡ºç¾ç•°å¸¸å¢åŠ ï¼Œ
  å¯ä½œç‚ºè»äº‹æ´»å‹•çš„æ—©æœŸé è­¦æŒ‡æ¨™ã€‚
================================================================================
"""

import json
from datetime import datetime, timedelta
from pathlib import Path

# =============================================================================
# è¨­å®š
# =============================================================================

DATA_DIR = Path("data")

# å·²çŸ¥è»æ¼”äº‹ä»¶æ¸…å–®
# æŒçºŒæ›´æ–°ï¼šæ–°å¢äº‹ä»¶å¾Œï¼Œæ¯æ—¥åˆ†ææœƒè‡ªå‹•æ¯”å°
MILITARY_EXERCISES = [
    {
        "name": "Joint Sword 2024A",
        "name_zh": "è¯åˆåˆ©åŠ-2024A",
        "start": "2024-05-23",
        "end": "2024-05-24",
        "trigger": "è³´æ¸…å¾·å°±è·",
        "trigger_en": "Lai Ching-te inauguration",
    },
    {
        "name": "Joint Sword 2024B",
        "name_zh": "è¯åˆåˆ©åŠ-2024B",
        "start": "2024-10-14",
        "end": "2024-10-15",
        "trigger": "é›™åç¯€æ¼”èªª",
        "trigger_en": "National Day speech",
    },
    {
        "name": "December 2024 Drill",
        "name_zh": "2024å¹´12æœˆè»æ¼”",
        "start": "2024-12-09",
        "end": "2024-12-11",
        "trigger": "å¹´åº¦ä¾‹è¡Œ",
        "trigger_en": "Routine annual",
    },
    {
        "name": "December 2025 Drill",
        "name_zh": "2025å¹´12æœˆè»æ¼”",
        "start": "2025-12-29",
        "end": "2025-12-31",
        "trigger": "å¹´åº¦ä¾‹è¡Œ",
        "trigger_en": "Routine annual",
    },
]

# åˆ†æåƒæ•¸
PRE_EXERCISE_DAYS = 14   # è»æ¼”å‰è§€å¯Ÿå¤©æ•¸
POST_EXERCISE_DAYS = 7   # è»æ¼”å¾Œè§€å¯Ÿå¤©æ•¸
ANOMALY_THRESHOLD = 1.5  # ç•°å¸¸é–€æª»ï¼ˆå€æ•¸æ–¼å¹³å‡å€¼ï¼‰


# =============================================================================
# åˆ†æå‡½æ•¸
# =============================================================================

def load_dark_vessel_data():
    """è¼‰å…¥æš—èˆ¹åµæ¸¬æ¯æ—¥è³‡æ–™"""
    dark_path = DATA_DIR / 'dark_vessels.json'
    if not dark_path.exists():
        print("âš ï¸ æ‰¾ä¸åˆ° dark_vessels.json")
        return {}, {}

    with open(dark_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # æ•´é«”æ¯æ—¥æš—èˆ¹æ•¸
    overall_daily = data.get('overall', {}).get('dark_by_date', {})

    # å„å€åŸŸæ¯æ—¥æš—èˆ¹æ•¸
    regions_daily = {}
    for region_id, region_data in data.get('regions', {}).items():
        regions_daily[region_id] = {
            'name': region_data.get('name', region_id),
            'daily': region_data.get('dark_by_date', {}),
        }

    return overall_daily, regions_daily


def compute_period_stats(daily_data, start_date, end_date):
    """è¨ˆç®—æŒ‡å®šæœŸé–“çš„æš—èˆ¹çµ±è¨ˆ"""
    values = []
    current = start_date
    while current <= end_date:
        date_str = current.strftime('%Y-%m-%d')
        if date_str in daily_data:
            values.append(daily_data[date_str])
        current += timedelta(days=1)

    if not values:
        return None

    return {
        'count': len(values),
        'total': sum(values),
        'mean': round(sum(values) / len(values), 1),
        'max': max(values),
        'min': min(values),
    }


def analyze_exercise_event(exercise, overall_daily, regions_daily):
    """åˆ†æå–®ä¸€è»æ¼”äº‹ä»¶å‰å¾Œçš„æš—èˆ¹è®ŠåŒ–"""
    ex_start = datetime.strptime(exercise['start'], '%Y-%m-%d')
    ex_end = datetime.strptime(exercise['end'], '%Y-%m-%d')

    # ä¸‰å€‹æ™‚æœŸçš„æ—¥æœŸç¯„åœ
    pre_start = ex_start - timedelta(days=PRE_EXERCISE_DAYS)
    pre_end = ex_start - timedelta(days=1)
    post_start = ex_end + timedelta(days=1)
    post_end = ex_end + timedelta(days=POST_EXERCISE_DAYS)

    # æ•´é«”æš—èˆ¹çµ±è¨ˆ
    pre_stats = compute_period_stats(overall_daily, pre_start, pre_end)
    during_stats = compute_period_stats(overall_daily, ex_start, ex_end)
    post_stats = compute_period_stats(overall_daily, post_start, post_end)

    # è¨ˆç®—è®ŠåŒ–ç™¾åˆ†æ¯”
    change_pct = None
    if pre_stats and during_stats and pre_stats['mean'] > 0:
        change_pct = round(
            (during_stats['mean'] - pre_stats['mean']) / pre_stats['mean'] * 100, 1
        )

    # å„å€åŸŸçµ±è¨ˆ
    region_analysis = {}
    for region_id, region_info in regions_daily.items():
        r_daily = region_info['daily']
        r_pre = compute_period_stats(r_daily, pre_start, pre_end)
        r_during = compute_period_stats(r_daily, ex_start, ex_end)
        r_post = compute_period_stats(r_daily, post_start, post_end)

        r_change = None
        if r_pre and r_during and r_pre['mean'] > 0:
            r_change = round(
                (r_during['mean'] - r_pre['mean']) / r_pre['mean'] * 100, 1
            )

        region_analysis[region_id] = {
            'name': region_info['name'],
            'before': r_pre,
            'during': r_during,
            'after': r_post,
            'change_pct': r_change,
        }

    result = {
        'name': exercise['name'],
        'name_zh': exercise['name_zh'],
        'start': exercise['start'],
        'end': exercise['end'],
        'trigger': exercise['trigger'],
        'trigger_en': exercise['trigger_en'],
        'has_data': pre_stats is not None or during_stats is not None,
        'overall': {
            'before': pre_stats,
            'during': during_stats,
            'after': post_stats,
            'change_pct': change_pct,
        },
        'regions': region_analysis,
    }

    return result


def compute_daily_baseline(overall_daily):
    """è¨ˆç®—æ¯æ—¥æš—èˆ¹åŸºæº–ç·šçµ±è¨ˆ"""
    values = list(overall_daily.values())
    if not values:
        return {'mean': 0, 'std': 0, 'anomaly_threshold': 0}

    mean_val = sum(values) / len(values)
    variance = sum((v - mean_val) ** 2 for v in values) / len(values)
    std_val = variance ** 0.5

    return {
        'mean': round(mean_val, 1),
        'std': round(std_val, 1),
        'anomaly_threshold': round(mean_val * ANOMALY_THRESHOLD, 1),
        'total_days': len(values),
    }


def detect_anomaly_days(overall_daily, baseline):
    """åµæ¸¬æš—èˆ¹æ•¸ç•°å¸¸åé«˜çš„æ—¥æœŸ"""
    threshold = baseline['anomaly_threshold']
    anomalies = []

    for date_str, count in sorted(overall_daily.items()):
        if count > threshold:
            anomalies.append({
                'date': date_str,
                'dark_vessels': count,
                'ratio_to_mean': round(count / baseline['mean'], 2) if baseline['mean'] > 0 else 0,
            })

    return anomalies


def check_proximity_to_exercises(anomalies, exercises):
    """æª¢æŸ¥ç•°å¸¸æ—¥æœŸæ˜¯å¦æ¥è¿‘è»æ¼”"""
    for anomaly in anomalies:
        anomaly_date = datetime.strptime(anomaly['date'], '%Y-%m-%d')
        anomaly['near_exercise'] = None

        for ex in exercises:
            ex_start = datetime.strptime(ex['start'], '%Y-%m-%d')
            ex_end = datetime.strptime(ex['end'], '%Y-%m-%d')
            delta_start = (ex_start - anomaly_date).days
            delta_end = (anomaly_date - ex_end).days

            if 0 <= delta_start <= PRE_EXERCISE_DAYS:
                anomaly['near_exercise'] = {
                    'name': ex['name'],
                    'days_before': delta_start,
                    'relation': 'before',
                }
                break
            elif ex_start <= anomaly_date <= ex_end:
                anomaly['near_exercise'] = {
                    'name': ex['name'],
                    'days_before': 0,
                    'relation': 'during',
                }
                break
            elif 0 <= delta_end <= POST_EXERCISE_DAYS:
                anomaly['near_exercise'] = {
                    'name': ex['name'],
                    'days_after': delta_end,
                    'relation': 'after',
                }
                break

    return anomalies


# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================

def main():
    print("=" * 60)
    print("ğŸ¯ è»æ¼”é æ¸¬åˆ†æ - æš—èˆ¹æ´»å‹•é è­¦æŒ‡æ¨™")
    print("=" * 60)
    print(f"åŸ·è¡Œæ™‚é–“: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

    # è¼‰å…¥è³‡æ–™
    overall_daily, regions_daily = load_dark_vessel_data()

    if not overall_daily:
        print("âš ï¸ ç„¡æš—èˆ¹æ¯æ—¥è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
        # ä»è¼¸å‡ºè»æ¼”æ¸…å–®ä¾› dashboard é¡¯ç¤º
        output = {
            'updated_at': datetime.utcnow().isoformat() + 'Z',
            'exercises': MILITARY_EXERCISES,
            'analysis': [],
            'baseline': {},
            'anomalies': [],
            'data_available': False,
        }
        output_path = DATA_DIR / 'exercise_prediction.json'
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²å„²å­˜ï¼ˆåƒ…è»æ¼”æ¸…å–®ï¼‰: {output_path}")
        return

    dates = sorted(overall_daily.keys())
    print(f"\nğŸ“Š æš—èˆ¹è³‡æ–™ç¯„åœ: {dates[0]} ~ {dates[-1]} ({len(dates)} å¤©)")
    print(f"   å·²çŸ¥è»æ¼”äº‹ä»¶: {len(MILITARY_EXERCISES)} å ´")

    # åŸºæº–ç·šçµ±è¨ˆ
    baseline = compute_daily_baseline(overall_daily)
    print(f"\nğŸ“ åŸºæº–ç·šçµ±è¨ˆ:")
    print(f"   å¹³å‡æš—èˆ¹æ•¸/å¤©: {baseline['mean']}")
    print(f"   æ¨™æº–å·®: {baseline['std']}")
    print(f"   ç•°å¸¸é–€æª» (Ã—{ANOMALY_THRESHOLD}): {baseline['anomaly_threshold']}")

    # è»æ¼”äº‹ä»¶åˆ†æ
    print(f"\nğŸ“‹ è»æ¼”äº‹ä»¶ç ”ç©¶:")
    print("-" * 70)

    exercise_results = []
    for ex in MILITARY_EXERCISES:
        result = analyze_exercise_event(ex, overall_daily, regions_daily)
        exercise_results.append(result)

        if result['has_data']:
            before = result['overall']['before']
            during = result['overall']['during']
            change = result['overall']['change_pct']

            before_str = f"{before['mean']:.0f}" if before else "N/A"
            during_str = f"{during['mean']:.0f}" if during else "N/A"
            change_str = f"{change:+.1f}%" if change is not None else "N/A"

            print(f"  {ex['name_zh']:<20} {ex['start']}")
            print(f"    å‰14å¤©å¹³å‡: {before_str}  è»æ¼”æœŸé–“: {during_str}  è®ŠåŒ–: {change_str}")
        else:
            print(f"  {ex['name_zh']:<20} {ex['start']}  (è³‡æ–™ç¯„åœå¤–)")

    # ç•°å¸¸æ—¥åµæ¸¬
    anomalies = detect_anomaly_days(overall_daily, baseline)
    anomalies = check_proximity_to_exercises(anomalies, MILITARY_EXERCISES)

    print(f"\nâš ï¸ ç•°å¸¸æ—¥åµæ¸¬ (æš—èˆ¹ > {baseline['anomaly_threshold']:.0f}):")
    if anomalies:
        for a in anomalies:
            near = a.get('near_exercise')
            near_str = ""
            if near:
                if near['relation'] == 'before':
                    near_str = f" â† {near['name']} å‰ {near['days_before']} å¤©"
                elif near['relation'] == 'during':
                    near_str = f" â† {near['name']} æœŸé–“"
                elif near['relation'] == 'after':
                    near_str = f" â† {near['name']} å¾Œ {near['days_after']} å¤©"
            print(f"  {a['date']}: {a['dark_vessels']} (Ã—{a['ratio_to_mean']:.1f}){near_str}")
    else:
        print("  ç„¡ç•°å¸¸æ—¥")

    # ç”¢å‡ºçµæœ
    output = {
        'updated_at': datetime.utcnow().isoformat() + 'Z',
        'data_range': {
            'start': dates[0],
            'end': dates[-1],
        },
        'exercises': MILITARY_EXERCISES,
        'analysis': exercise_results,
        'baseline': baseline,
        'anomalies': anomalies,
        'parameters': {
            'pre_exercise_days': PRE_EXERCISE_DAYS,
            'post_exercise_days': POST_EXERCISE_DAYS,
            'anomaly_threshold_multiplier': ANOMALY_THRESHOLD,
        },
        'data_available': True,
    }

    output_path = DATA_DIR / 'exercise_prediction.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… åˆ†æçµæœå·²å„²å­˜: {output_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()
