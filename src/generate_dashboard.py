#!/usr/bin/env python3
"""
================================================================================
Dashboard è³‡æ–™ç”Ÿæˆè…³æœ¬
Generate dashboard-ready data from vessel monitoring
================================================================================
"""

import json
import shutil
from datetime import datetime, timezone, timedelta
from pathlib import Path

DATA_DIR = Path("data")
DOCS_DIR = Path("docs")
DOCS_DIR.mkdir(exist_ok=True)

def main():
    print("ğŸ“Š ç”Ÿæˆ Dashboard è³‡æ–™...")

    # è®€å– GFW vessel è³‡æ–™
    vessel_path = DATA_DIR / 'vessel_data.json'
    if vessel_path.exists():
        with open(vessel_path, 'r', encoding='utf-8') as f:
            vessel_data = json.load(f)
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° vessel_data.jsonï¼Œè·³é")
        vessel_data = {'daily': [], 'summary': {}}

    # è®€å– CSIS å¯ç–‘èˆ¹éš»åˆ†æçµæœ
    suspicious_path = DATA_DIR / 'suspicious_vessels.json'
    if suspicious_path.exists():
        with open(suspicious_path, 'r', encoding='utf-8') as f:
            suspicious_data = json.load(f)
        print(f"ğŸ” å·²è¼‰å…¥å¯ç–‘èˆ¹éš»åˆ†æ: {suspicious_data.get('summary', {}).get('suspicious_count', 0)} è‰˜å¯ç–‘")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° suspicious_vessels.jsonï¼Œè·³é")
        suspicious_data = None

    # è®€å–æš—èˆ¹åµæ¸¬è³‡æ–™
    dark_vessels_path = DATA_DIR / 'dark_vessels.json'
    dark_vessels_data = None
    if dark_vessels_path.exists():
        with open(dark_vessels_path, 'r', encoding='utf-8') as f:
            dark_vessels_data = json.load(f)
        overall = dark_vessels_data.get('overall', {})
        print(f"ğŸ”¦ å·²è¼‰å…¥æš—èˆ¹è³‡æ–™: {overall.get('dark_vessels', 0)} è‰˜æš—èˆ¹ / "
              f"{overall.get('total_detections', 0)} ç¸½åµæ¸¬ "
              f"({overall.get('dark_ratio', 0)}%)")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° dark_vessels.jsonï¼Œè·³é")

    # è®€å– AIS å¿«ç…§è³‡æ–™ï¼ˆç”± fetch_ais_data.py ç”¢ç”Ÿï¼‰
    ais_path = DATA_DIR / 'ais_snapshot.json'
    ais_snapshot = None
    if ais_path.exists():
        try:
            with open(ais_path, 'r', encoding='utf-8') as f:
                ais_raw = json.load(f)
            ais_snapshot = {
                'updated_at': ais_raw.get('updated_at', ''),
                'ais_data': ais_raw.get('statistics', {}),
                'vessels': ais_raw.get('vessels', [])[:100]
            }
            print(f"ğŸ“¡ å·²è¼‰å…¥ AIS å¿«ç…§: {len(ais_snapshot['vessels'])} è‰˜èˆ¹")
        except (json.JSONDecodeError, IOError) as e:
            print(f"âš ï¸ è®€å– ais_snapshot.json å¤±æ•—: {e}")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° ais_snapshot.jsonï¼Œè·³é")

    # è®€å–è»æ¼”é æ¸¬åˆ†æçµæœ
    prediction_path = DATA_DIR / 'exercise_prediction.json'
    prediction_data = None
    if prediction_path.exists():
        try:
            with open(prediction_path, 'r', encoding='utf-8') as f:
                prediction_data = json.load(f)
            status = prediction_data.get('status', 'unknown')
            print(f"ğŸ“ˆ å·²è¼‰å…¥è»æ¼”é æ¸¬åˆ†æ: status={status}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"âš ï¸ è®€å– exercise_prediction.json å¤±æ•—: {e}")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° exercise_prediction.jsonï¼Œè·³é")

    # è®€å–èº«åˆ†è®Šæ›´äº‹ä»¶ï¼ˆç”± fetch_ais_data.py ç”¢ç”Ÿï¼‰
    identity_path = DATA_DIR / 'identity_events.json'
    identity_events_data = None
    if identity_path.exists():
        try:
            with open(identity_path, 'r', encoding='utf-8') as f:
                all_events = json.load(f)

            now = datetime.now(timezone.utc)
            cutoff_24h = now - timedelta(hours=24)
            cutoff_7d = now - timedelta(days=7)

            events_24h = []
            events_7d = []
            for ev in all_events:
                try:
                    ts = datetime.fromisoformat(ev['timestamp'].replace('Z', '+00:00'))
                except (ValueError, KeyError):
                    continue
                if ts >= cutoff_7d:
                    events_7d.append(ev)
                    if ts >= cutoff_24h:
                        events_24h.append(ev)

            mmsi_24h = set(ev['mmsi'] for ev in events_24h)
            mmsi_7d = set(ev['mmsi'] for ev in events_7d)

            identity_events_data = {
                'events_24h': events_24h[:50],
                'events_7d': events_7d[:100],
                'summary': {
                    'count_24h': len(events_24h),
                    'count_7d': len(events_7d),
                    'vessels_24h': len(mmsi_24h),
                    'vessels_7d': len(mmsi_7d),
                },
            }
            print(f"ğŸ”„ å·²è¼‰å…¥èº«åˆ†è®Šæ›´äº‹ä»¶: 24h={len(events_24h)}, 7d={len(events_7d)}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"âš ï¸ è®€å– identity_events.json å¤±æ•—: {e}")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° identity_events.jsonï¼Œè·³é")

    output_path = DOCS_DIR / 'data.json'

    # åˆä½µæ‰€æœ‰è³‡æ–™
    dashboard = {
        'updated_at': datetime.now(timezone.utc).isoformat() + 'Z',
        'vessel_monitoring': vessel_data,
        'suspicious_analysis': suspicious_data,
        'dark_vessels': dark_vessels_data,
        'exercise_prediction': prediction_data,
        'ais_snapshot': ais_snapshot or {'updated_at': '', 'ais_data': {}, 'vessels': []},
        'identity_events': identity_events_data,
        'status': 'operational',
        'version': '3.2.0'
    }

    # å„²å­˜è‡³ docs ç›®éŒ„ï¼ˆä¾› GitHub Pages ä½¿ç”¨ï¼‰
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(dashboard, f, ensure_ascii=False, indent=2)

    print(f"âœ… Dashboard è³‡æ–™å·²å„²å­˜: {output_path}")

    # è¤‡è£½æš—èˆ¹å‹•ç•«è³‡æ–™è‡³ docsï¼ˆç¨ç«‹æª”æ¡ˆï¼Œé¿å…ä¸» data.json éå¤§ï¼‰
    weekly_dark_path = DATA_DIR / 'weekly_dark_vessels.json'
    if weekly_dark_path.exists():
        shutil.copy2(weekly_dark_path, DOCS_DIR / 'weekly_dark_vessels.json')
        print(f"ğŸ¬ å·²è¤‡è£½æš—èˆ¹å‹•ç•«è³‡æ–™è‡³ docs/weekly_dark_vessels.json")

    # è¤‡è£½èº«åˆ†è®Šæ›´äº‹ä»¶è‡³ docsï¼ˆä¾›èº«åˆ†è¿½è¹¤é é¢ä½¿ç”¨ï¼‰
    if identity_path.exists():
        shutil.copy2(identity_path, DOCS_DIR / 'identity_events.json')
        print(f"ğŸ”„ å·²è¤‡è£½èº«åˆ†è®Šæ›´äº‹ä»¶è‡³ docs/identity_events.json")


if __name__ == "__main__":
    main()
