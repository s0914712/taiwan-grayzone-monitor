#!/usr/bin/env python3
"""
================================================================================
GFW è³‡æ–™æ“·å–è…³æœ¬ - å°ç£å‘¨é‚Šå¯ç–‘èˆ¹éš»ç›£æ¸¬
Taiwan Gray Zone Vessel Monitor - GFW Data Fetcher
================================================================================

åŠŸèƒ½ï¼š
1. å¾ GFW API æ“·å–å°ç£å‘¨é‚Š SAR è¡›æ˜Ÿåµæ¸¬è³‡æ–™ï¼ˆæš—èˆ¹ï¼‰
2. æ“·å–ä¸­åœ‹ç±èˆ¹éš»åœ¨å°ç£å‘¨é‚Šçš„å­˜åœ¨è³‡æ–™ï¼ˆVessel Presenceï¼‰
3. æ“·å–æ¼æ’ˆåŠªåŠ›é‡è³‡æ–™ï¼ˆFishing Effortï¼‰
4. è¨ˆç®—å¯ç–‘èˆ¹éš»æŒ‡æ¨™ä¸¦å„²å­˜è‡³ JSON

è³‡æ–™ä¾†æºï¼š
- Global Fishing Watch API (4wings report)
  - public-global-sar-presence:latest
  - public-global-presence:latest (flag=CHN)
  - public-global-fishing-effort:latest
================================================================================
"""

import os
import json
import requests
from datetime import datetime, timedelta
from pathlib import Path

# =============================================================================
# è¨­å®š
# =============================================================================

API_TOKEN = os.environ.get('GFW_API_TOKEN', '').strip()
BASE_URL = "https://gateway.api.globalfishingwatch.org/v3"

DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

# å°ç£å‘¨é‚Šç›£æ¸¬å€åŸŸ
TAIWAN_AREA = {
    "type": "Polygon",
    "coordinates": [[
        [117.0, 21.0], [126.0, 21.0], [126.0, 27.0], [117.0, 27.0], [117.0, 21.0]
    ]]
}

# è»æ¼”å€åŸŸå®šç¾©ï¼ˆJoint Sword ç­‰ï¼‰
DRILL_ZONES = {
    "north": {"name": "åŒ—å€", "coords": [[121.0, 25.5], [122.5, 25.5], [122.5, 26.8], [121.0, 26.8], [121.0, 25.5]]},
    "east": {"name": "æ±å€", "coords": [[122.5, 23.0], [125.0, 23.0], [125.0, 25.5], [122.5, 25.5], [122.5, 23.0]]},
    "south": {"name": "å—å€", "coords": [[119.0, 21.5], [121.0, 21.5], [121.0, 23.0], [119.0, 23.0], [119.0, 21.5]]},
    "west": {"name": "è¥¿å€", "coords": [[118.5, 23.5], [120.0, 23.5], [120.0, 25.0], [118.5, 25.0], [118.5, 23.5]]},
}

# =============================================================================
# API å‡½æ•¸
# =============================================================================

def get_headers():
    """Build request headers (deferred so token is read at call time)"""
    return {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }


def fetch_4wings_report(dataset, region, start_date, end_date, filters=None):
    """
    é€šç”¨ 4wings report API å‘¼å«
    dataset: GFW dataset ID (e.g. 'public-global-sar-presence:latest')
    filters: optional list of filter strings (e.g. ["flag='CHN'"])
    """
    params = {
        "datasets[0]": dataset,
        "date-range": f"{start_date},{end_date}",
        "temporal-resolution": "DAILY",
        "spatial-resolution": "HIGH",
        "spatial-aggregation": "false",
        "format": "JSON"
    }

    if filters:
        for i, f in enumerate(filters):
            params[f"filters[{i}]"] = f

    try:
        response = requests.post(
            f"{BASE_URL}/4wings/report",
            params=params,
            json={"geojson": region},
            headers=get_headers(),
            timeout=120
        )

        if response.status_code == 200:
            return response.json()
        else:
            print(f"   âŒ API éŒ¯èª¤ {response.status_code}: {response.text[:300]}")
            return {}

    except Exception as e:
        print(f"   âŒ è«‹æ±‚å¤±æ•—: {e}")
        return {}


def parse_4wings_entries(data):
    """è§£æ 4wings API å›æ‡‰çš„ entries"""
    entries = data.get('entries', [])
    if not entries:
        return []

    results = []
    for entry in entries:
        for key, values in entry.items():
            if isinstance(values, list):
                results.extend(values)
    return results


# =============================================================================
# è³‡æ–™æ“·å–å‡½æ•¸
# =============================================================================

def fetch_sar_data(region, start_date, end_date):
    """æ“·å– SAR è¡›æ˜Ÿåµæ¸¬è³‡æ–™ï¼ˆæš—èˆ¹åµæ¸¬ï¼‰"""
    print("   ğŸ›°ï¸ SAR è¡›æ˜Ÿåµæ¸¬...")
    data = fetch_4wings_report(
        "public-global-sar-presence:latest",
        region, start_date, end_date
    )
    records = parse_4wings_entries(data)
    print(f"      å–å¾— {len(records)} ç­† SAR è¨˜éŒ„")
    return records


def fetch_vessel_presence(region, start_date, end_date):
    """æ“·å–ä¸­åœ‹ç±èˆ¹éš»å­˜åœ¨è³‡æ–™ï¼ˆCHN flag filterï¼‰"""
    print("   ğŸš¢ ä¸­åœ‹ç±èˆ¹éš»å­˜åœ¨...")
    data = fetch_4wings_report(
        "public-global-presence:latest",
        region, start_date, end_date,
        filters=["flag='CHN'"]
    )
    records = parse_4wings_entries(data)
    print(f"      å–å¾— {len(records)} ç­†ä¸­åœ‹èˆ¹éš»è¨˜éŒ„")
    return records


def fetch_fishing_effort(region, start_date, end_date):
    """æ“·å–æ¼æ’ˆåŠªåŠ›é‡è³‡æ–™"""
    print("   ğŸ£ æ¼æ’ˆåŠªåŠ›é‡...")
    data = fetch_4wings_report(
        "public-global-fishing-effort:latest",
        region, start_date, end_date
    )
    records = parse_4wings_entries(data)
    print(f"      å–å¾— {len(records)} ç­†æ¼æ’ˆè¨˜éŒ„")
    return records


# =============================================================================
# åˆ†æå‡½æ•¸
# =============================================================================

def is_in_drill_zone(lat, lon):
    """æª¢æŸ¥åº§æ¨™æ˜¯å¦åœ¨ä»»ä½•è»æ¼”å€å…§"""
    for zone_id, zone in DRILL_ZONES.items():
        coords = zone['coords']
        # coords æ ¼å¼: [[lon, lat], ...]
        lons = [c[0] for c in coords]
        lats = [c[1] for c in coords]
        if min(lats) <= lat <= max(lats) and min(lons) <= lon <= max(lons):
            return zone_id
    return None


def analyze_sar_daily(sar_records):
    """å°‡ SAR è¨˜éŒ„å½™æ•´ç‚ºæ¯æ—¥çµ±è¨ˆ"""
    daily_stats = {}
    for record in sar_records:
        date = record.get('date', '')[:10]
        if not date:
            continue

        if date not in daily_stats:
            daily_stats[date] = {
                'date': date,
                'total_detections': 0,
                'dark_vessels': 0,
            }

        daily_stats[date]['total_detections'] += 1

        # æš—èˆ¹ï¼šç„¡ vessel ID çš„åµæ¸¬
        if not record.get('vesselId'):
            daily_stats[date]['dark_vessels'] += 1

    return sorted(daily_stats.values(), key=lambda x: x['date'])


def analyze_presence(presence_records):
    """åˆ†æä¸­åœ‹èˆ¹éš»åœ¨å°ç£å‘¨é‚Šçš„å­˜åœ¨æƒ…æ³"""
    daily_presence = {}
    drill_zone_records = 0
    total_hours = 0

    for record in presence_records:
        date = record.get('date', '')[:10]
        if not date:
            continue

        hours = record.get('hours', record.get('value', 0))
        if not isinstance(hours, (int, float)):
            hours = 0

        if date not in daily_presence:
            daily_presence[date] = {
                'date': date,
                'chn_vessel_hours': 0,
                'in_drill_zone_hours': 0,
            }

        daily_presence[date]['chn_vessel_hours'] += hours
        total_hours += hours

        # æª¢æŸ¥æ˜¯å¦åœ¨è»æ¼”å€
        lat = record.get('lat', record.get('latitude'))
        lon = record.get('lon', record.get('longitude'))
        if lat is not None and lon is not None:
            zone = is_in_drill_zone(lat, lon)
            if zone:
                daily_presence[date]['in_drill_zone_hours'] += hours
                drill_zone_records += 1

    return {
        'daily': sorted(daily_presence.values(), key=lambda x: x['date']),
        'total_records': len(presence_records),
        'total_hours': round(total_hours, 1),
        'drill_zone_records': drill_zone_records,
    }


def analyze_fishing(fishing_records):
    """åˆ†ææ¼æ’ˆåŠªåŠ›é‡"""
    daily_effort = {}
    total_hours = 0

    for record in fishing_records:
        date = record.get('date', '')[:10]
        if not date:
            continue

        hours = record.get('hours', record.get('value', 0))
        if not isinstance(hours, (int, float)):
            hours = 0

        if date not in daily_effort:
            daily_effort[date] = {
                'date': date,
                'fishing_hours': 0,
            }

        daily_effort[date]['fishing_hours'] += hours
        total_hours += hours

    return {
        'daily': sorted(daily_effort.values(), key=lambda x: x['date']),
        'total_fishing_hours': round(total_hours, 1),
    }


# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================

def main():
    print("=" * 60)
    print("ğŸ›°ï¸ GFW è³‡æ–™æ“·å– - å°ç£å‘¨é‚Šå¯ç–‘èˆ¹éš»ç›£æ¸¬")
    print("=" * 60)
    print(f"åŸ·è¡Œæ™‚é–“: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

    if not API_TOKEN:
        print("âš ï¸ æœªè¨­å®š GFW_API_TOKENï¼Œè·³é GFW è³‡æ–™æ”¶é›†")
        return

    # è¨ˆç®—æ—¥æœŸç¯„åœï¼ˆæœ€è¿‘ 30 å¤©ï¼‰
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=30)

    start_str = start_date.strftime('%Y-%m-%d')
    end_str = end_date.strftime('%Y-%m-%d')

    print(f"\nğŸ“… æŸ¥è©¢ç¯„åœ: {start_str} ~ {end_str}")
    print(f"\nğŸ“¡ æ“·å– GFW è³‡æ–™ï¼ˆä¸‰çµ„è³‡æ–™é›†ï¼‰...")

    # æ“·å–ä¸‰çµ„è³‡æ–™
    sar_records = fetch_sar_data(TAIWAN_AREA, start_str, end_str)
    presence_records = fetch_vessel_presence(TAIWAN_AREA, start_str, end_str)
    fishing_records = fetch_fishing_effort(TAIWAN_AREA, start_str, end_str)

    # åˆ†æå„è³‡æ–™é›†
    daily_list = analyze_sar_daily(sar_records)
    presence_analysis = analyze_presence(presence_records)
    fishing_analysis = analyze_fishing(fishing_records)

    # è¨ˆç®—æš—èˆ¹è¶¨å‹¢
    if len(daily_list) >= 7:
        recent_7d = sum(d['dark_vessels'] for d in daily_list[-7:]) / 7
        previous_7d = sum(d['dark_vessels'] for d in daily_list[-14:-7]) / 7 if len(daily_list) >= 14 else recent_7d
        trend = ((recent_7d - previous_7d) / previous_7d * 100) if previous_7d > 0 else 0
    else:
        recent_7d = 0
        trend = 0

    # å»ºç«‹è¼¸å‡ºè³‡æ–™
    output = {
        'updated_at': datetime.utcnow().isoformat() + 'Z',
        'data_range': {
            'start': start_str,
            'end': end_str
        },
        'summary': {
            'total_days': len(daily_list),
            'avg_daily_detections': sum(d['total_detections'] for d in daily_list) / len(daily_list) if daily_list else 0,
            'avg_daily_dark_vessels': sum(d['dark_vessels'] for d in daily_list) / len(daily_list) if daily_list else 0,
            'recent_7d_avg': recent_7d,
            'trend_pct': trend,
            'chn_presence_records': presence_analysis['total_records'],
            'chn_presence_hours': presence_analysis['total_hours'],
            'chn_drill_zone_records': presence_analysis['drill_zone_records'],
            'total_fishing_hours': fishing_analysis['total_fishing_hours'],
        },
        'daily': daily_list,
        'chn_presence': presence_analysis,
        'fishing_effort': fishing_analysis,
        'drill_zones': DRILL_ZONES,
        'alerts': []
    }

    # æª¢æŸ¥æš—èˆ¹ç•°å¸¸
    if len(daily_list) >= 2:
        latest = daily_list[-1]
        avg = output['summary']['avg_daily_dark_vessels']
        if avg > 0 and latest['dark_vessels'] > avg * 1.5:
            output['alerts'].append({
                'type': 'high_dark_vessels',
                'date': latest['date'],
                'value': latest['dark_vessels'],
                'threshold': avg * 1.5,
                'message': f"æš—èˆ¹æ•¸é‡ç•°å¸¸å¢åŠ : {latest['dark_vessels']} (å¹³å‡ {avg:.0f})"
            })

    # æª¢æŸ¥ä¸­åœ‹èˆ¹éš»è»æ¼”å€æ´»å‹•
    if presence_analysis['drill_zone_records'] > 0:
        output['alerts'].append({
            'type': 'chn_drill_zone_presence',
            'value': presence_analysis['drill_zone_records'],
            'message': f"ä¸­åœ‹èˆ¹éš»åœ¨è»æ¼”å€æ´»å‹•: {presence_analysis['drill_zone_records']} ç­†è¨˜éŒ„"
        })

    # å„²å­˜è³‡æ–™
    output_path = DATA_DIR / 'vessel_data.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… è³‡æ–™å·²å„²å­˜: {output_path}")
    print(f"   SAR åµæ¸¬: {len(sar_records)} ç­†")
    print(f"   ä¸­åœ‹èˆ¹éš»: {presence_analysis['total_records']} ç­† "
          f"(è»æ¼”å€ {presence_analysis['drill_zone_records']} ç­†)")
    print(f"   æ¼æ’ˆåŠªåŠ›: {fishing_analysis['total_fishing_hours']:.0f} å°æ™‚")
    print(f"   æš—èˆ¹è¶¨å‹¢: {trend:+.1f}%")


if __name__ == "__main__":
    main()
