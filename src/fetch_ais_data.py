#!/usr/bin/env python3
"""
èˆªæ¸¯å±€ AIS è³‡æ–™æ”¶é›†è…³æœ¬ - MPB ç«¯é»ç‰ˆ
åŠŸèƒ½ï¼šå¾èˆªæ¸¯å±€ã€Œè‡ºç£æµ·åŸŸèˆ¹èˆ¶å³æ™‚è³‡è¨Šç³»çµ±ã€æ”¶é›† AIS è³‡æ–™ã€åˆ†æè»æ¼”/æ¼æ’ˆç†±å€ã€ç¶­è­·æ­·å²ç´€éŒ„ã€‚
è³‡æ–™ä¾†æº: https://mpbais.motcmpb.gov.tw/aismpb/tools/geojsonais.ashx
"""

import os
import json
import requests
import urllib3
from datetime import datetime, timezone
from collections import defaultdict

# èˆªæ¸¯å±€ SSL æ†‘è­‰ç¼ºå°‘ Subject Key Identifierï¼Œåœç”¨é©—è­‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é…ç½®å€ ---
DATA_DIR = 'data'
DOCS_DIR = 'docs'
OUTPUT_FILE = os.path.join(DATA_DIR, 'ais_snapshot.json')
HISTORY_FILE = os.path.join(DATA_DIR, 'vessel_history.json')
AIS_HISTORY_FILE = os.path.join(DATA_DIR, 'ais_history.json')
DASHBOARD_FILE = os.path.join(DOCS_DIR, 'data.json')

MPB_URL = "https://mpbais.motcmpb.gov.tw/aismpb/tools/geojsonais.ashx"
MPB_HEADERS = {
    "Accept": "application/json, text/javascript, */*; q=0.01",
    "Accept-Encoding": "gzip, deflate, br",
    "Accept-Language": "en-US,en;q=0.9,zh;q=0.8,zh-TW;q=0.7",
    "Referer": "https://mpbais.motcmpb.gov.tw/aismpb/",
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/145.0.0.0 Safari/537.36"
    ),
    "X-Requested-With": "XMLHttpRequest",
}

# å°ç£å‘¨é‚Š bounding box (ç”¨æ–¼éæ¿¾éå°ç£æµ·åŸŸè³‡æ–™)
TAIWAN_BBOX = {'lat_min': 20, 'lat_max': 28, 'lon_min': 112, 'lon_max': 128}

# å€åŸŸå®šç¾©
DRILL_ZONES = {
    'north': {'name': 'åŒ—å€', 'bounds': [[25.5, 121.0], [26.8, 122.5]]},
    'east':  {'name': 'æ±å€', 'bounds': [[23.0, 122.5], [25.5, 125.0]]},
    'south': {'name': 'å—å€', 'bounds': [[21.5, 119.0], [23.0, 121.0]]},
    'west':  {'name': 'è¥¿å€', 'bounds': [[23.5, 118.5], [25.0, 120.0]]},
}

FISHING_HOTSPOTS = {
    'taiwan_bank':   {'name': 'å°ç£ç˜æ¼å ´',   'bounds': [[22.0, 117.0], [23.5, 119.5]]},
    'penghu':        {'name': 'æ¾æ¹–æ¼å ´',     'bounds': [[23.0, 119.0], [24.0, 120.0]]},
    'kuroshio_east': {'name': 'æ±éƒ¨é»‘æ½®æ¼å ´', 'bounds': [[22.5, 121.0], [24.5, 122.0]]},
    'northeast':     {'name': 'æ±åŒ—æ¼å ´',     'bounds': [[24.8, 121.5], [25.8, 123.0]]},
    'southwest':     {'name': 'è¥¿å—æ²¿å²¸æ¼å ´', 'bounds': [[22.0, 120.0], [23.0, 120.8]]},
}

# MPB Ship_and_Cargo_Type å°ç…§è¡¨
# AIS æ¨™æº–: 30-39 æ¼èˆ¹, 35 è»äº‹, 50-59 ç‰¹æ®Š, 60-69 å®¢èˆ¹, 70-79 è²¨èˆ¹, 80-89 æ²¹è¼ª
def classify_vessel_type(type_code):
    """æ ¹æ“š AIS Ship_and_Cargo_Type ç¢¼åˆ†é¡èˆ¹èˆ¶"""
    if type_code is None:
        return 'unknown'
    t = int(type_code)
    if 30 <= t <= 39:
        return 'fishing'
    elif t == 35:
        return 'military'
    elif 40 <= t <= 49:
        return 'high_speed'
    elif 50 <= t <= 59:
        return 'special'
    elif 60 <= t <= 69:
        return 'passenger'
    elif 70 <= t <= 79:
        return 'cargo'
    elif 80 <= t <= 89:
        return 'tanker'
    elif t == 0:
        return 'unknown'
    else:
        return 'other'

# --- å·¥å…·å‡½å¼ ---

def is_in_zone(lat, lon, bounds):
    return (bounds[0][0] <= lat <= bounds[1][0] and
            bounds[0][1] <= lon <= bounds[1][1])


def is_in_taiwan_bbox(lat, lon):
    b = TAIWAN_BBOX
    return (b['lat_min'] <= lat <= b['lat_max'] and
            b['lon_min'] <= lon <= b['lon_max'])


# --- è³‡æ–™æ”¶é›† ---

def collect_ais_data():
    """å¾èˆªæ¸¯å±€ MPB ç«¯é»å–å¾—å³æ™‚ AIS GeoJSON è³‡æ–™"""
    print(f"ğŸš€ æ­£åœ¨å¾èˆªæ¸¯å±€æ“·å– AIS è³‡æ–™...")

    try:
        resp = requests.get(MPB_URL, headers=MPB_HEADERS, timeout=30, verify=False)
        resp.raise_for_status()
        geojson = resp.json()
    except requests.RequestException as e:
        print(f"âŒ è«‹æ±‚å¤±æ•—: {e}")
        return {}

    features = geojson.get("features", [])
    print(f"  HTTP {resp.status_code} | {len(resp.content):,} bytes | {len(features)} features")

    vessels = {}
    skipped = 0

    for feat in features:
        props = feat.get("properties", {})
        coords = feat.get("geometry", {}).get("coordinates", [None, None])

        lon = coords[0] if coords and len(coords) > 0 else None
        lat = coords[1] if coords and len(coords) > 1 else None

        if lon is None or lat is None:
            skipped += 1
            continue

        # éæ¿¾è¶…å‡ºå°ç£æµ·åŸŸç¯„åœçš„è³‡æ–™
        if not is_in_taiwan_bbox(lat, lon):
            skipped += 1
            continue

        mmsi = str(props.get("MMSI", "")).strip()
        if not mmsi or mmsi == "0":
            skipped += 1
            continue

        ship_name = str(props.get("ShipName", "")).strip()
        type_code = props.get("Ship_and_Cargo_Type")
        type_name = classify_vessel_type(type_code)
        sog = props.get("SOG", 0.0) or 0.0
        cog = props.get("COG", 0.0) or 0.0
        record_time = props.get("Record_Time", "")

        # å€åŸŸåˆ¤å®š
        drill_zone = next(
            (zid for zid, z in DRILL_ZONES.items()
             if is_in_zone(lat, lon, z['bounds'])),
            None
        )
        fishing_hotspot = next(
            (hid for hid, h in FISHING_HOTSPOTS.items()
             if is_in_zone(lat, lon, h['bounds'])),
            None
        )

        # å¯ç–‘åˆ¤å®šï¼šæ¼èˆ¹åœ¨è»æ¼”å€ä½†ä¸åœ¨æ¼å ´
        suspicious = (type_name == 'fishing' and
                      drill_zone is not None and
                      fishing_hotspot is None)

        vessels[mmsi] = {
            'mmsi': mmsi,
            'name': ship_name if ship_name else f'MMSI-{mmsi}',
            'imo': str(props.get("IMO_Number", "")).strip(),
            'call_sign': str(props.get("Call_Sign", "")).strip(),
            'lat': lat,
            'lon': lon,
            'type': type_code,
            'type_name': type_name,
            'speed': float(sog),
            'heading': float(cog),
            'nav_status': str(props.get("Navigational_Status", "")),
            'in_drill_zone': drill_zone,
            'in_fishing_hotspot': fishing_hotspot,
            'suspicious': suspicious,
            'record_time': record_time,
            'last_update': datetime.now(timezone.utc).isoformat(),
        }

    print(f"  âœ… æœ‰æ•ˆèˆ¹èˆ¶: {len(vessels)} | è·³é: {skipped}")
    return vessels


# --- åˆ†æ ---

def analyze_data(vessels):
    stats = {
        'total_vessels': len(vessels),
        'fishing_vessels': sum(1 for v in vessels.values() if v['type_name'] == 'fishing'),
        'suspicious_count': 0,
        'avg_speed': 0.0,
        'by_type': defaultdict(int),
        'in_drill_zones': {k: 0 for k in DRILL_ZONES},
        'in_fishing_hotspots': {k: 0 for k in FISHING_HOTSPOTS},
    }

    if not vessels:
        stats['by_type'] = {}
        return stats

    total_speed = 0
    for v in vessels.values():
        stats['by_type'][v['type_name']] += 1
        if v['in_drill_zone']:
            stats['in_drill_zones'][v['in_drill_zone']] += 1
        if v['in_fishing_hotspot']:
            stats['in_fishing_hotspots'][v['in_fishing_hotspot']] += 1
        if v['suspicious']:
            stats['suspicious_count'] += 1
        total_speed += v['speed']

    stats['avg_speed'] = round(total_speed / len(vessels), 2)
    stats['by_type'] = dict(stats['by_type'])
    return stats


# --- å„²å­˜ ---

def save_all(vessels, stats):
    """çµ±ä¸€å„²å­˜å…¥å£ï¼Œç¢ºä¿è¼¸å‡ºæª”æ¡ˆæ ¼å¼ä¸€è‡´"""
    now_str = datetime.now(timezone.utc).isoformat()
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(DOCS_DIR, exist_ok=True)

    vessel_list = list(vessels.values())

    # API å›å‚³ 0 è‰˜æ™‚ä¿ç•™èˆŠå¿«ç…§ï¼Œé¿å…æ¸…ç©ºæœ‰æ•ˆè³‡æ–™
    # ï¼ˆå¸¸è¦‹æ–¼ GitHub Actionsï¼šMPB API å°é–å¢ƒå¤– IPï¼‰
    if not vessel_list:
        print(f"  âš ï¸ æœ¬æ¬¡å–å¾— 0 è‰˜èˆ¹ï¼Œä¿ç•™æ—¢æœ‰å¿«ç…§ï¼Œè·³éè¦†å¯«")
        return

    # 1. å„²å­˜å¿«ç…§
    full_output = {
        'updated_at': now_str,
        'source': 'MPB_geojsonais',
        'statistics': stats,
        'vessels': vessel_list,
    }
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(full_output, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“„ å¿«ç…§å·²å„²å­˜: {OUTPUT_FILE} ({len(vessel_list)} è‰˜)")

    # 2. æ›´æ–°æ­·å²ç´€éŒ„ (è¿½åŠ æ¯æ—¥æ‘˜è¦)
    history = []
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            history = loaded if isinstance(loaded, list) else []
        except Exception:
            history = []

    history.append({
        'timestamp': now_str,
        'total_vessels': stats['total_vessels'],
        'fishing_vessels': stats['fishing_vessels'],
        'suspicious_count': stats['suspicious_count'],
        'by_type': stats['by_type'],
        'in_drill_zones': stats['in_drill_zones'],
    })

    # ä¿ç•™æœ€è¿‘ 1000 ç­†æ­·å²
    history = history[-1000:]
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

    # 2b. æ¯æ—¥ AIS æ­·å²å¿«ç…§ï¼ˆçµ±è¨ˆæ‘˜è¦ + å¯ç–‘èˆ¹èˆ¶ï¼Œä¾›å‰ç«¯è¶¨å‹¢åœ–ä½¿ç”¨ï¼‰
    today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    suspicious_vessels = [
        {
            'mmsi': v['mmsi'],
            'name': v['name'],
            'lat': v['lat'],
            'lon': v['lon'],
            'type_name': v['type_name'],
            'speed': v['speed'],
            'in_drill_zone': v['in_drill_zone'],
        }
        for v in vessel_list if v.get('suspicious')
    ]

    daily_snapshot = {
        'date': today_str,
        'stats': {
            'total_vessels': stats['total_vessels'],
            'fishing_vessels': stats['fishing_vessels'],
            'suspicious_count': stats['suspicious_count'],
            'avg_speed': stats['avg_speed'],
            'by_type': stats['by_type'],
            'in_drill_zones': stats['in_drill_zones'],
            'in_fishing_hotspots': stats.get('in_fishing_hotspots', {}),
        },
        'suspicious_vessels': suspicious_vessels,
    }

    ais_history = []
    if os.path.exists(AIS_HISTORY_FILE):
        try:
            with open(AIS_HISTORY_FILE, 'r', encoding='utf-8') as f:
                ais_history = json.load(f)
            if not isinstance(ais_history, list):
                ais_history = []
        except Exception:
            ais_history = []

    # åŒä¸€å¤©å¤šæ¬¡åŸ·è¡Œåªä¿ç•™æœ€æ–°ä¸€ç­†
    ais_history = [s for s in ais_history if s.get('date') != today_str]
    ais_history.append(daily_snapshot)

    # ä¿ç•™æœ€è¿‘ 90 å¤©
    ais_history = ais_history[-90:]
    with open(AIS_HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(ais_history, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“… æ¯æ—¥å¿«ç…§å·²æ›´æ–°: {AIS_HISTORY_FILE} ({len(ais_history)} å¤©)")

    # 3. æ›´æ–° Dashboard è³‡æ–™ï¼ˆèˆ‡ generate_dashboard.py æ ¼å¼ä¸€è‡´ï¼‰
    existing = {}
    if os.path.exists(DASHBOARD_FILE):
        try:
            with open(DASHBOARD_FILE, 'r', encoding='utf-8') as f:
                existing = json.load(f)
        except Exception:
            pass

    existing['updated_at'] = now_str
    existing['ais_snapshot'] = {
        'updated_at': now_str,
        'source': 'MPB_geojsonais',
        'ais_data': stats,
        'vessels': vessel_list,
    }

    with open(DASHBOARD_FILE, 'w', encoding='utf-8') as f:
        json.dump(existing, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“Š Dashboard å·²æ›´æ–°: {DASHBOARD_FILE}")


# --- ä¸»ç¨‹å¼ ---

def main():
    print(f"{'='*50}")
    print(f"  èˆªæ¸¯å±€ AIS èˆ¹ä½æ”¶é›† (MPB ç«¯é»)")
    print(f"  {datetime.now(timezone.utc):%Y-%m-%d %H:%M:%S} UTC")
    print(f"{'='*50}\n")

    vessels = collect_ais_data()
    stats = analyze_data(vessels)
    save_all(vessels, stats)

    print(f"\n{'='*50}")
    print(f"  âœ… å®Œæˆ")
    print(f"  èˆ¹èˆ¶ç¸½æ•¸: {stats['total_vessels']}")
    print(f"  æ¼èˆ¹: {stats['fishing_vessels']}")
    print(f"  å¯ç–‘: {stats['suspicious_count']}")
    print(f"  å¹³å‡èˆªé€Ÿ: {stats['avg_speed']} kn")
    print(f"  é¡å‹åˆ†å¸ƒ: {stats['by_type']}")
    print(f"{'='*50}")


if __name__ == '__main__':
    main()
