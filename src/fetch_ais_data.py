#!/usr/bin/env python3
"""
AISStream.io è³‡æ–™æ”¶é›†è…³æœ¬
æ”¶é›†å°ç£å‘¨é‚Šçš„å³æ™‚ AIS èˆ¹éš»è³‡æ–™ä¸¦å„²å­˜ç‚º JSON

ä½¿ç”¨æ–¹å¼ï¼š
    è¨­å®šç’°å¢ƒè®Šæ•¸ AISSTREAM_API_KEY
    python fetch_ais_data.py
"""

import os
import json
import asyncio
import ssl
import websockets
from datetime import datetime, timezone, timedelta
from collections import defaultdict

# é…ç½®
API_KEY = os.environ.get('AISSTREAM_API_KEY', '').strip()
TAIWAN_BBOX = [[21.0, 117.0], [27.0, 126.0]]  # [ç·¯åº¦, ç¶“åº¦]
COLLECTION_TIME = 180  # æ”¶é›† 3 åˆ†é˜çš„è³‡æ–™
OUTPUT_FILE = 'data/ais_snapshot.json'

# è»æ¼”å€åŸŸå®šç¾©
DRILL_ZONES = {
    'north': {'name': 'åŒ—å€', 'bounds': [[25.5, 121.0], [26.8, 122.5]]},
    'east': {'name': 'æ±å€', 'bounds': [[23.0, 122.5], [25.5, 125.0]]},
    'south': {'name': 'å—å€', 'bounds': [[21.5, 119.0], [23.0, 121.0]]},
    'west': {'name': 'è¥¿å€', 'bounds': [[23.5, 118.5], [25.0, 120.0]]}
}

# æ¼æ’ˆç†±é»å®šç¾©ï¼ˆå°ç£å‘¨é‚Šå·²çŸ¥é«˜ç”¢æ¼å ´ï¼‰
# åƒè€ƒï¼šæ¼æ¥­ç½²å…¬é–‹æ¼å ´è³‡æ–™ã€GFW fishing effort ç†±å€
FISHING_HOTSPOTS = {
    'taiwan_bank': {
        'name': 'å°ç£ç˜æ¼å ´',
        'bounds': [[22.0, 117.0], [23.5, 119.5]],
        'description': 'å°ç£æµ·å³½è¥¿å—éƒ¨æ·ºç˜ï¼Œåº•æ‹–ç¶²ä¸»è¦æ¼å ´'
    },
    'penghu': {
        'name': 'æ¾æ¹–æ¼å ´',
        'bounds': [[23.0, 119.0], [24.0, 120.0]],
        'description': 'æ¾æ¹–ç¾¤å³¶å‘¨é‚Šï¼Œåˆºç¶²èˆ‡å»¶ç¹©é‡£æ¼å ´'
    },
    'kuroshio_east': {
        'name': 'æ±éƒ¨é»‘æ½®æ¼å ´',
        'bounds': [[22.5, 121.0], [24.5, 122.0]],
        'description': 'é»‘æ½®æµç¶“å°ç£æ±éƒ¨ï¼Œé®ªé­šå»¶ç¹©é‡£æ¼å ´'
    },
    'northeast': {
        'name': 'æ±åŒ—æ¼å ´',
        'bounds': [[24.8, 121.5], [25.8, 123.0]],
        'description': 'åŸºéš†-å®œè˜­å¤–æµ·ï¼Œé–ç®¡æ£’å—ç¶²æ¼å ´'
    },
    'southwest': {
        'name': 'è¥¿å—æ²¿å²¸æ¼å ´',
        'bounds': [[22.0, 120.0], [23.0, 120.8]],
        'description': 'æ±æ¸¯-å°ç‰çƒï¼Œè¿‘æµ·æ‹–ç¶²æ¼å ´'
    },
}

# èˆ¹éš»é¡å‹å°ç…§
VESSEL_TYPE_MAP = {
    30: 'fishing',
    31: 'towing',
    32: 'towing',
    33: 'dredging',
    34: 'diving',
    35: 'military',
    36: 'sailing',
    37: 'pleasure',
    50: 'pilot',
    51: 'sar',
    52: 'tug',
    53: 'port_tender',
    55: 'law_enforcement',
    60: 'passenger',
    61: 'passenger',
    70: 'cargo',
    71: 'cargo',
    72: 'cargo',
    73: 'cargo',
    74: 'cargo',
    80: 'tanker',
    81: 'tanker',
    82: 'tanker',
    83: 'tanker',
    84: 'tanker',
}


def is_in_zone(lat, lon, bounds):
    """æª¢æŸ¥åº§æ¨™æ˜¯å¦åœ¨æŒ‡å®šå€åŸŸå…§"""
    return (bounds[0][0] <= lat <= bounds[1][0] and
            bounds[0][1] <= lon <= bounds[1][1])


def get_fishing_hotspot(lat, lon):
    """æª¢æŸ¥èˆ¹éš»æ˜¯å¦åœ¨æ¼æ’ˆç†±é»å…§ï¼Œå›å‚³ç†±é» ID æˆ– None"""
    for hotspot_id, hotspot in FISHING_HOTSPOTS.items():
        if is_in_zone(lat, lon, hotspot['bounds']):
            return hotspot_id
    return None


async def collect_ais_data():
    """é€£æ¥ AISStream ä¸¦æ”¶é›†è³‡æ–™
    åƒè€ƒå®˜æ–¹ç¯„ä¾‹: https://github.com/aisstream/example/tree/main/python
    """

    if not API_KEY:
        print("âš ï¸ æœªè¨­å®š AISSTREAM_API_KEYï¼Œè·³é AIS è³‡æ–™æ”¶é›†")
        return {}

    vessels = {}
    message_count = 0
    error_count = 0
    start_time = datetime.now(timezone.utc)

    print(f"ğŸ”— é€£æ¥ AISStream.io...")
    print(f"ğŸ”‘ API Key: {API_KEY[:8]}...{API_KEY[-4:]}" if len(API_KEY) > 12 else f"ğŸ”‘ API Key: (length={len(API_KEY)})")
    print(f"ğŸ“ ç›£æ¸¬å€åŸŸ: {TAIWAN_BBOX}")
    print(f"â±ï¸ æ”¶é›†æ™‚é–“: {COLLECTION_TIME} ç§’")

    def process_message(data):
        """è™•ç†å–®ä¸€ AIS è¨Šæ¯"""
        meta = data.get('MetaData', {})
        mmsi = str(meta.get('MMSI', ''))
        lat = meta.get('latitude')
        lon = meta.get('longitude')

        if not mmsi or lat is None or lon is None:
            return

        # æ›´æ–°èˆ¹éš»è³‡æ–™
        if mmsi not in vessels:
            vessels[mmsi] = {
                'mmsi': mmsi,
                'name': meta.get('ShipName', '').strip() or f'MMSI-{mmsi}',
                'lat': lat,
                'lon': lon,
                'type': 0,
                'type_name': 'unknown',
                'speed': 0,
                'heading': 0,
                'in_drill_zone': None,
                'in_fishing_hotspot': None,
                'last_update': datetime.now(timezone.utc).isoformat()
            }

        vessel = vessels[mmsi]
        vessel['lat'] = lat
        vessel['lon'] = lon
        vessel['last_update'] = datetime.now(timezone.utc).isoformat()

        if meta.get('ShipName'):
            vessel['name'] = meta['ShipName'].strip()

        # è™•ç†ä½ç½®å ±å‘Š
        if data.get('MessageType') == 'PositionReport':
            pr = data.get('Message', {}).get('PositionReport', {})
            vessel['speed'] = pr.get('Sog', 0)
            vessel['heading'] = pr.get('TrueHeading') or pr.get('Cog', 0)

        # è™•ç†éœæ…‹è³‡æ–™
        if data.get('MessageType') == 'ShipStaticData':
            sd = data.get('Message', {}).get('ShipStaticData', {})
            vessel['type'] = sd.get('Type', 0)
            vessel['type_name'] = VESSEL_TYPE_MAP.get(vessel['type'], 'other')
            vessel['destination'] = sd.get('Destination', '')

        # æª¢æŸ¥æ˜¯å¦åœ¨è»æ¼”å€
        for zone_id, zone in DRILL_ZONES.items():
            if is_in_zone(lat, lon, zone['bounds']):
                vessel['in_drill_zone'] = zone_id
                break
        else:
            vessel['in_drill_zone'] = None

        # æª¢æŸ¥æ˜¯å¦åœ¨æ¼æ’ˆç†±é»
        vessel['in_fishing_hotspot'] = get_fishing_hotspot(lat, lon)

    # SSL è¨­å®šï¼ˆåƒè€ƒå®˜æ–¹ main_ssl_disabled.pyï¼ŒGitHub Actions ç’°å¢ƒå¯èƒ½æœ‰ SSL é©—è­‰å•é¡Œï¼‰
    ssl_ctx = ssl.SSLContext()
    ssl_ctx.check_hostname = False
    ssl_ctx.verify_mode = ssl.CERT_NONE

    # å˜—è©¦å…©ç¨®é€£ç·šæ–¹å¼ï¼šå…ˆç”¨ SSL ç¦ç”¨æ¨¡å¼ï¼Œå¤±æ•—å†ç”¨é è¨­æ¨¡å¼
    for attempt, use_ssl_ctx in enumerate([(ssl_ctx, "SSL-relaxed"), (None, "SSL-default")], 1):
        ssl_opt, ssl_label = use_ssl_ctx
        try:
            print(f"\nğŸ”— é€£ç·šå˜—è©¦ #{attempt} ({ssl_label})...")
            ws_kwargs = {
                'ping_interval': 20,
                'ping_timeout': 20,
                'close_timeout': 10,
            }
            if ssl_opt:
                ws_kwargs['ssl'] = ssl_opt

            async with websockets.connect(
                'wss://stream.aisstream.io/v0/stream',
                **ws_kwargs
            ) as ws:
                print(f"   âœ… WebSocket é€£ç·šæˆåŠŸ ({ssl_label})")

                # è¨‚é–±å°ç£å‘¨é‚Šï¼ˆå¿…é ˆåœ¨é€£ç·š 3 ç§’å…§é€å‡ºï¼‰
                subscribe_msg = {
                    "APIKey": API_KEY,
                    "BoundingBoxes": [TAIWAN_BBOX]
                }
                await ws.send(json.dumps(subscribe_msg))
                print("   âœ… å·²é€å‡ºè¨‚é–±è«‹æ±‚")

                # å˜—è©¦æ¥æ”¶ç¬¬ä¸€å‰‡è¨Šæ¯ç¢ºèªé€£ç·šæœ‰æ•ˆ
                try:
                    first_msg = await asyncio.wait_for(ws.recv(), timeout=15)
                    first_data = json.loads(first_msg)
                    message_count += 1

                    msg_type = first_data.get('MessageType', 'unknown')
                    print(f"   ğŸ“¨ é¦–å‰‡è¨Šæ¯: type={msg_type}, keys={list(first_data.keys())}")

                    if 'error' in first_data or 'Error' in first_data:
                        err_msg = first_data.get('error') or first_data.get('Error', '')
                        print(f"   âŒ API éŒ¯èª¤å›æ‡‰: {err_msg}")
                        return {}

                    process_message(first_data)
                except asyncio.TimeoutError:
                    print("   âš ï¸ 15 ç§’å…§æœªæ”¶åˆ°ä»»ä½•è¨Šæ¯ï¼Œé€£ç·šå¯èƒ½æœ‰å•é¡Œ")
                    # ä»ç„¶ç¹¼çºŒç­‰å¾…

                # æ”¶é›†è¿´åœˆ
                async def collect_loop():
                    nonlocal message_count, error_count
                    async for msg_raw in ws:
                        elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()
                        if elapsed >= COLLECTION_TIME:
                            break

                        try:
                            data = json.loads(msg_raw)
                        except json.JSONDecodeError:
                            error_count += 1
                            if error_count <= 3:
                                print(f"   âš ï¸ JSON è§£æå¤±æ•—: {str(msg_raw)[:200]}")
                            continue

                        message_count += 1

                        if message_count <= 3:
                            msg_type = data.get('MessageType', 'unknown')
                            print(f"   ğŸ“¨ è¨Šæ¯ #{message_count}: type={msg_type}")

                        if 'error' in data or 'Error' in data:
                            err_msg = data.get('error') or data.get('Error', '')
                            print(f"   âŒ API éŒ¯èª¤: {err_msg}")
                            continue

                        process_message(data)

                        if message_count % 100 == 0:
                            print(f"ğŸ“¥ å·²æ”¶é›† {message_count} è¨Šæ¯, {len(vessels)} è‰˜èˆ¹éš» ({elapsed:.0f}s)")

                try:
                    await asyncio.wait_for(collect_loop(), timeout=COLLECTION_TIME + 30)
                except asyncio.TimeoutError:
                    print("â° æ”¶é›†è¶…æ™‚")

                print(f"\nâœ… æ”¶é›†å®Œæˆ!")
                print(f"   ç¸½è¨Šæ¯: {message_count}")
                print(f"   è§£æéŒ¯èª¤: {error_count}")
                print(f"   èˆ¹éš»æ•¸: {len(vessels)}")

                if message_count == 0:
                    print("   âš ï¸ æœªæ”¶åˆ°ä»»ä½•è¨Šæ¯ï¼å¯èƒ½åŸå› ï¼š")
                    print("      1. API Key ç„¡æ•ˆæˆ–å·²éæœŸ")
                    print("      2. AISStream æœå‹™æš«æ™‚ä¸å¯ç”¨")
                    print("      3. è«‹è‡³ https://aisstream.io ç¢ºèª API Key ç‹€æ…‹")

                # é€£ç·šæˆåŠŸï¼Œä¸éœ€è¦å˜—è©¦ç¬¬äºŒç¨®æ–¹å¼
                break

        except websockets.exceptions.InvalidStatusCode as e:
            print(f"   âŒ WebSocket è¢«æ‹’çµ•: HTTP {e.status_code}")
            if e.status_code == 403:
                print("   â†’ API Key ç„¡æ•ˆï¼Œè«‹è‡³ aisstream.io ç¢ºèª")
                return {}
            if attempt < 2:
                print("   â†’ å˜—è©¦ä¸‹ä¸€ç¨®é€£ç·šæ–¹å¼...")
                continue
            return {}
        except websockets.exceptions.ConnectionClosedError as e:
            print(f"   âŒ é€£ç·šè¢«é—œé–‰: {e}")
            if attempt < 2:
                print("   â†’ å˜—è©¦ä¸‹ä¸€ç¨®é€£ç·šæ–¹å¼...")
                continue
            print("   â†’ å…©ç¨®é€£ç·šæ–¹å¼éƒ½å¤±æ•—")
            print("   â†’ è«‹ç¢ºèª API Key æ˜¯å¦æœ‰æ•ˆ: https://aisstream.io")
            return {}
        except Exception as e:
            print(f"   âŒ é€£æ¥éŒ¯èª¤: {type(e).__name__}: {e}")
            if attempt < 2:
                print("   â†’ å˜—è©¦ä¸‹ä¸€ç¨®é€£ç·šæ–¹å¼...")
                continue
            return {}

    return vessels


def analyze_data(vessels):
    """åˆ†ææ”¶é›†åˆ°çš„è³‡æ–™"""
    stats = {
        'total_vessels': len(vessels),
        'by_type': defaultdict(int),
        'in_drill_zones': defaultdict(int),
        'in_fishing_hotspots': defaultdict(int),
        'fishing_vessels': 0,
        'suspicious_count': 0,
        'avg_speed': 0,
    }

    total_speed = 0
    for v in vessels.values():
        stats['by_type'][v['type_name']] += 1

        if v['in_drill_zone']:
            stats['in_drill_zones'][v['in_drill_zone']] += 1

        if v.get('in_fishing_hotspot'):
            stats['in_fishing_hotspots'][v['in_fishing_hotspot']] += 1

        if v['type_name'] == 'fishing':
            stats['fishing_vessels'] += 1

        # å³æ™‚å¯ç–‘åˆ¤å®šï¼šæ¼èˆ¹åœ¨è»æ¼”å€ä½†ä¸åœ¨æ¼æ’ˆç†±é»
        if (v['type_name'] == 'fishing' and
                v['in_drill_zone'] and
                not v.get('in_fishing_hotspot')):
            v['suspicious'] = True
            stats['suspicious_count'] += 1
        else:
            v['suspicious'] = False

        total_speed += v['speed']

    if len(vessels) > 0:
        stats['avg_speed'] = round(total_speed / len(vessels), 2)

    # è½‰æ› defaultdict ç‚ºæ™®é€š dict
    stats['by_type'] = dict(stats['by_type'])
    stats['in_drill_zones'] = dict(stats['in_drill_zones'])
    stats['in_fishing_hotspots'] = dict(stats['in_fishing_hotspots'])

    return stats


def update_vessel_history(vessels):
    """ç´¯ç©èˆ¹éš»æ­·å²è§€æ¸¬è¨˜éŒ„ï¼Œç”¨æ–¼ CSIS è¡Œç‚ºåˆ†æ"""
    os.makedirs('data', exist_ok=True)
    history_file = 'data/vessel_history.json'

    # è¼‰å…¥æ—¢æœ‰æ­·å²
    history = {}
    if os.path.exists(history_file):
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except (json.JSONDecodeError, IOError):
            history = {}

    now = datetime.now(timezone.utc).isoformat()

    for v in vessels.values():
        mmsi = v['mmsi']
        if mmsi not in history:
            history[mmsi] = {
                'mmsi': mmsi,
                'names_seen': [],
                'types_seen': [],
                'total_snapshots': 0,
                'drill_zone_snapshots': 0,
                'fishing_hotspot_snapshots': 0,
                'first_seen': now,
                'last_seen': now,
                'snapshots': [],
            }

        profile = history[mmsi]
        profile['total_snapshots'] += 1
        profile['last_seen'] = now

        # è¿½è¹¤èˆ¹åè®Šæ›´ï¼ˆAIS ç•°å¸¸æŒ‡æ¨™ï¼‰
        name = v.get('name', '')
        if name and name not in profile['names_seen']:
            profile['names_seen'].append(name)

        # è¿½è¹¤èˆ¹å‹è®Šæ›´
        type_name = v.get('type_name', 'unknown')
        if type_name not in profile['types_seen']:
            profile['types_seen'].append(type_name)

        if v.get('in_drill_zone'):
            profile['drill_zone_snapshots'] += 1

        if v.get('in_fishing_hotspot'):
            profile['fishing_hotspot_snapshots'] += 1

        # ä¿ç•™æœ€è¿‘ 30 ç­†å¿«ç…§æ‘˜è¦ï¼ˆç”¨æ–¼ going dark åµæ¸¬ï¼‰
        profile['snapshots'].append({
            'time': now,
            'lat': v['lat'],
            'lon': v['lon'],
            'zone': v.get('in_drill_zone'),
            'hotspot': v.get('in_fishing_hotspot'),
            'speed': v.get('speed', 0),
            'name': name,
        })
        profile['snapshots'] = profile['snapshots'][-30:]

    # æ¸…ç†è¶…é 30 å¤©æœªå‡ºç¾çš„èˆ¹éš»
    cutoff = (datetime.now(timezone.utc) - timedelta(days=30)).isoformat()
    history = {k: v for k, v in history.items() if v['last_seen'] >= cutoff}

    with open(history_file, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“œ å·²æ›´æ–°èˆ¹éš»æ­·å²: {len(history)} è‰˜è¿½è¹¤ä¸­")


def save_data(vessels, stats):
    """å„²å­˜è³‡æ–™åˆ° JSON æª”æ¡ˆ"""
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs('data', exist_ok=True)
    
    output = {
        'updated_at': datetime.now(timezone.utc).isoformat(),
        'collection_duration_seconds': COLLECTION_TIME,
        'statistics': stats,
        'drill_zones': {k: v['name'] for k, v in DRILL_ZONES.items()},
        'vessels': list(vessels.values())
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å·²å„²å­˜è‡³ {OUTPUT_FILE}")
    
    # åŒæ™‚æ›´æ–° docs/data.json ä¾› Dashboard ä½¿ç”¨
    dashboard_data = {
        'updated_at': output['updated_at'],
        'ais_data': {
            'vessel_count': stats['total_vessels'],
            'fishing_count': stats['fishing_vessels'],
            'in_drill_zone_count': sum(stats['in_drill_zones'].values()),
            'suspicious_count': stats['suspicious_count'],
            'drill_zone_breakdown': stats['in_drill_zones'],
            'type_breakdown': stats['by_type'],
            'avg_speed': stats['avg_speed']
        },
        'vessels': list(vessels.values())[:100]  # åªä¿ç•™å‰100è‰˜ä¾›å³æ™‚é¡¯ç¤º
    }
    
    # è®€å–ç¾æœ‰ data.json ä¸¦åˆä½µ
    docs_data_file = 'docs/data.json'
    existing_data = {}
    if os.path.exists(docs_data_file):
        with open(docs_data_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
    
    existing_data['updated_at'] = output['updated_at']
    existing_data['ais_snapshot'] = dashboard_data
    
    with open(docs_data_file, 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å·²æ›´æ–° {docs_data_file}")


async def main():
    print("=" * 50)
    print("ğŸ›°ï¸ AISStream å°ç£å‘¨é‚Šèˆ¹éš»è³‡æ–™æ”¶é›†")
    print("=" * 50)
    print(f"æ™‚é–“: {datetime.now(timezone.utc).isoformat()}")
    print()
    
    # æ”¶é›†è³‡æ–™
    vessels = await collect_ais_data()
    
    # åˆ†æè³‡æ–™
    stats = analyze_data(vessels)
    
    print("\nğŸ“Š çµ±è¨ˆæ‘˜è¦:")
    print(f"   ç¸½èˆ¹éš»æ•¸: {stats['total_vessels']}")
    print(f"   æ¼èˆ¹æ•¸é‡: {stats['fishing_vessels']}")
    print(f"   è»æ¼”å€å…§: {sum(stats['in_drill_zones'].values())}")
    print(f"   å¯ç–‘èˆ¹éš»: {stats['suspicious_count']}")
    print(f"   å¹³å‡èˆªé€Ÿ: {stats['avg_speed']} kn")
    print(f"   é¡å‹åˆ†å¸ƒ: {stats['by_type']}")

    # ç´¯ç©æ­·å²è¨˜éŒ„
    update_vessel_history(vessels)

    # å„²å­˜è³‡æ–™
    save_data(vessels, stats)

    print("\nâœ… å®Œæˆ!")


if __name__ == '__main__':
    asyncio.run(main())
